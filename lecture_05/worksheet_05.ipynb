{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Worksheet 05\n",
    "\n",
    "Name:  Prathmesh Sonawane\n",
    "\n",
    "UID: U39215370\n",
    "\n",
    "### Topics\n",
    "\n",
    "- Cost Functions\n",
    "- Kmeans\n",
    "\n",
    "### Cost Function\n",
    "\n",
    "Solving Data Science problems often starts by defining a metric with which to evaluate solutions were you able to find some. This metric is called a cost function. Data Science then backtracks and tries to find a process / algorithm to find solutions that can optimize for that cost function.\n",
    "\n",
    "For example suppose you are asked to cluster three points A, B, C into two non-empty clusters. If someone gave you the solution `{A, B}, {C}`, how would you evaluate that this is a good solution?\n",
    "\n",
    "Notice that because the clusters need to be non-empty and all points must be assigned to a cluster, it must be that two of the three points will be together in one cluster and the third will be alone in the other cluster.\n",
    "\n",
    "In the above solution, if A and B are closer than A and C, and B and C, then this is a good solution. The smaller the distance between the two points in the same cluster (here A and B), the better the solution. So we can define our cost function to be that distance (between A and B here)!\n",
    "\n",
    "The algorithm / process would involve clustering together the two closest points and put the third in its own cluster. This process optimizes for that cost function because no other pair of points could have a lower distance (although it could equal it)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K means\n",
    "\n",
    "a) (1-dimensional clustering) Walk through Lloyd's algorithm step by step on the following dataset:\n",
    "\n",
    "`[0, .5, 1.5, 2, 6, 6.5, 7]` (note: each of these are 1-dimensional data points)\n",
    "\n",
    "Given the initial centroids:\n",
    "\n",
    "`[0, 2]`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Firstly, we assign the values 2 and 0 as our centroids for our 2 clusters. Then, we assign every value in our dataset to its closest cluster, that being 2 and 0. In this case, the values 0 and 0.5 will be assigned to the cluster with centroid 0, and the values 1.5, 2, 6, 6.5, and 7 will be assigned to the cluster with centroid 2. Next, the mean value of all the points in each cluster will be calculated. For the cluster with centroid 0, our average will be 0.25, and for our other cluster, it will be 4.6. These two values will become the new centroids for our two clusters, and the whole process will start again. This will continue to happen until our two centroids reach a convergence point, with little to no change. \n",
    "\n",
    "In the second iteration, the points 0, 0.5, 1.5, and 2 will be assigned to the cluster with centroid 0.25. In addition, the points 6, 6.5, and 7 will be assigned to the cluster with centroid 4.6. Taking the mean of the points in each cluster, the new centroid becomes 1 and 6.5 respectively. \n",
    "\n",
    "In the third iteration, the points 0, 0.5, 1.5, and 2 will be assigned to the cluster with centroid 1. In addition, the points 6, 6.5, and 7 will be assigned to the cluster with centroid 6.5. Taking the mean of the points in each cluster, the new centroid continues to be 1 and 6.5 respectively. Since our centroids have reached a convergence, we are done and have our two clusters. \n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b) Describe in plain english what the cost function for k means is."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cost-function is how we evaluate and compare solutions to a given problem. In our context, for k-means clustering, we want a cost function that gives us a smaller cost when our solution is better, or more meaningful. A common cost function for partitional clustering is minimizing the total distance between all points in a node for all given nodes. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c) For the same number of clusters K, why could there be very different solutions to the K means algorithm on a given dataset?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the same number of clusters k, you could have different solutions due to the randomness of picking your initial centroids for your k clusters. Due to this randomness, when we reach a convergence, we do so by finding the optimal centroids from where we started. However, if we can start with different initial centroids, we can end with different ending centroids as well. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "d) Does Lloyd's Algorithm always converge? Why / why not?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yes, this algorithm always does converge. In every iteration of the algorithm, we find new centroids based on the mean of the previous data points in our clusters during the last iteration. This means that during every iteration, we get closer to finding the optimal centroid for every cluster. With this guarantee, we always step toward the solution, and thus we will eventually find it. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "e) Follow along in class the implementation of Kmeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 2.52223629 -3.31696117]\n",
      " [ 1.79254085  2.08068856]\n",
      " [-2.75431214  1.67400929]\n",
      " [ 0.45122083 -1.90484772]]\n",
      "[[ 2.08517021 -4.22909513]\n",
      " [ 1.66067199  1.82996945]\n",
      " [-2.8062043   1.6770794 ]\n",
      " [ 0.26463481 -1.09043737]]\n",
      "[[ 1.87857639 -4.2014945 ]\n",
      " [ 1.72390637  1.88773635]\n",
      " [-2.90101537  1.7680821 ]\n",
      " [ 0.1661884  -0.49673396]]\n",
      "[[ 1.84012274 -4.13675116]\n",
      " [ 1.79856883  1.95373897]\n",
      " [-2.98474421  1.81545992]\n",
      " [ 0.06354201 -0.2029132 ]]\n",
      "[[ 1.84012274 -4.13675116]\n",
      " [ 1.88073218  1.9820243 ]\n",
      " [-3.04862622  1.85340542]\n",
      " [ 0.00773286 -0.06380801]]\n",
      "[[ 1.84012274e+00 -4.13675116e+00]\n",
      " [ 1.91248297e+00  2.00204407e+00]\n",
      " [-3.07703402e+00  1.85266958e+00]\n",
      " [ 1.33733963e-02 -3.71451966e-04]]\n",
      "[[ 1.84012274e+00 -4.13675116e+00]\n",
      " [ 1.91248297e+00  2.00204407e+00]\n",
      " [-3.07703402e+00  1.85266958e+00]\n",
      " [ 1.33733963e-02 -3.71451966e-04]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from PIL import Image as im\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn.datasets as datasets\n",
    "\n",
    "centers = [[0, 0], [2, 2], [-3, 2], [2, -4]]\n",
    "X, _ = datasets.make_blobs(n_samples=300, centers=centers, cluster_std=1, random_state=0)\n",
    "\n",
    "class KMeans():\n",
    "\n",
    "    def __init__(self, data, k):\n",
    "        self.data = data\n",
    "        self.k = k\n",
    "        self.assignment = [-1 for _ in range(len(data))]\n",
    "        self.snaps = []\n",
    "    \n",
    "    def snap(self, centers):\n",
    "        TEMPFILE = \"temp.png\"\n",
    "\n",
    "        fig, ax = plt.subplots()\n",
    "        ax.scatter(X[:, 0], X[:, 1], c=self.assignment)\n",
    "        ax.scatter(centers[:,0], centers[:, 1], c='r')\n",
    "        fig.savefig(TEMPFILE)\n",
    "        plt.close()\n",
    "        self.snaps.append(im.fromarray(np.asarray(im.open(TEMPFILE))))\n",
    "        \n",
    "    def is_unassigned(self, i):\n",
    "        return self.assignment[i] == -1\n",
    "    \n",
    "    def unassign_all(self):\n",
    "        self.assignment = [-1 for _ in range(len(self.data))]\n",
    "        \n",
    "    def initialize(self):\n",
    "        return self.data[np.random.choice(range(len(self.data)), size=self.k, replace=False)]\n",
    "    \n",
    "    def are_centers_diff(self, c1, c2):\n",
    "        for i in range(len(c1)):\n",
    "            if c1[i] not in c2:\n",
    "                return True\n",
    "        return False\n",
    "    \n",
    "    def assign(self, centers):\n",
    "        for i in range(len(self.data)):\n",
    "            self.assignment[i] = 0\n",
    "            temp_assign = 0\n",
    "            temp_dist = self.dist(self.data[i], centers[0])\n",
    "            for j in range(1, len(centers)):\n",
    "                new_dist = self.dist(self.data[i], centers[j])\n",
    "                if temp_dist > new_dist:\n",
    "                    self.assignment[i] = j\n",
    "                    temp_dist = new_dist\n",
    "    \n",
    "    def calculate_new_centers(self):\n",
    "        centers = []\n",
    "        for j in range(self.k):\n",
    "            cluster_j = self.data[\n",
    "                np.array([i for i in range(len(self.data)) if self.assignment[i] == j])\n",
    "            ]\n",
    "            centers.append(np.mean(cluster_j,axis=0))\n",
    "        \n",
    "        return np.array(centers)\n",
    "\n",
    "    def dist(self, x, y):\n",
    "        return sum((x - y) ** 2) ** (1/2)\n",
    "\n",
    "    def lloyds(self):\n",
    "        centers = self.initialize()\n",
    "        self.assign(centers)\n",
    "        self.snap(centers)\n",
    "        new_centers = self.calculate_new_centers()\n",
    "        while self.are_centers_diff(centers, new_centers):\n",
    "            centers = new_centers\n",
    "            self.snap(centers)\n",
    "            self.unassign_all()\n",
    "            self.assign(centers)\n",
    "            new_centers = self.calculate_new_centers()\n",
    "            print (new_centers)\n",
    "        return\n",
    "            \n",
    "kmeans = KMeans(X, 4)\n",
    "kmeans.lloyds()\n",
    "images = kmeans.snaps\n",
    "\n",
    "images[0].save(\n",
    "    'kmeans.gif',\n",
    "    optimize=False,\n",
    "    save_all=True,\n",
    "    append_images=images[1:],\n",
    "    loop=0,\n",
    "    duration=500\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "6a0b3adf0a7b81e80108459d05de564879dd9a45d1690df432e56f4a054c0c35"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
